<!DOCTYPE html>
<html>

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GPRFW9DK4Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-GPRFW9DK4Q');
  </script>
  <meta charset="utf-8">
  <meta name="description" content="High-Fidelity Facial Albedo Estimation via Texture Quantization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>High-Fidelity Facial Albedo Estimation via Texture Quantization</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
</head>

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    .container {
      display: flex;
      justify-content: center; /* 水平居中 */
      align-items: center;    /* 垂直居中 */
      height: 100vh;          /* 让容器占满整个视窗高度 */
    }
    .text_column, .video_column {
      display: flex;
      flex-direction: column;
      align-items: center;  /* 中心对齐列中的内容 */
      margin: 0 0;       /* 调整列之间的间距 */
    }
    p {
      margin: 20px 0;       /* 调整每段文字的间距 */
    }
  </style>
  <title>Centered Text and Videos</title>
</head>


<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">High-Fidelity Facial Albedo Estimation via Texture Quantization
              <br>
              <!-- <small>CVPR 2023</small> -->
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Zimin Ran
              </span>,
              <span class="author-block">
                <a href="https://xingyuren.github.io/">Xingyu Ren</a>
              </span>,
              <span class="author-block">
                <a href="https://github.com/anxiangsir">Xiang An</a>
              </span>,
              <span class="author-block">
                <a href="https://kaicheng-yang0828.github.io/">Kaicheng Yang</a>
              </span>,
              <span class="author-block">
                Xiangzi Dai
              </span>,<br>
              <span class="author-block">
                Ziyong Feng
              </span>,
              <span class="author-block">
                Jia Guo
              </span>,
              <span class="author-block">
                <a href="https://ffmpbgrnn.github.io/">Linchao Zhu</a>
              </span>,
              <span class="author-block">
                <a href="https://jiankangdeng.github.io/">Jiankang Deng</a>
              </span>
            </div>

            <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Technology Sydney</span>&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Shanghai Jiao Tong University</span>
            <span class="author-block"><sup>2</sup>DeepGlint</span>

          </div> -->

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2304.06711.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- <span class="link-block">
                <a href="."
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=6ZQbiNiJJEE"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/adobe-research/diffusion-rig"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="columns is-centered">
      <div class="column is-7">
        <img src="static/images/fig1_teaser.png" alt="Teaser Image" />

        <h2 class="subtitle has-text-justified" style="font-size:18px;">
          We introduce HiFiAlbedo, a high-fidelity facial albedo recovery method. HiFiAlbedo learns a high-quality
          texture codebook from large-scale RGB faces,
          generates textures from the images, and then enables domain adaptation from texture to the albedo domain. Our
          method does not rely on captured data and
          generates high-fidelity albedo maps that can be used for realistic rendering.
        </h2>
      </div>
    </div>
  </section>


  <!-- <section class="hero teaser">
  <div class="columns is-centered">
    <div class="column is-7">
      <video autoplay loop muted>
        <source src="static/videos/teaser_video.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>

      <h2 class="subtitle has-text-justified" style="font-size:18px;">
        DiffusionRig takes in coarse physical rendering as the condition to “rig” the input image with learned personal priors. The edited
images respect the rendering conditions, preserve the identity, and exhibit high-frequency facial details.
      </h2>
    </div>
  </div>
</section> -->

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-11">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified" style="font-size:20px;">
            Recent 3D face reconstruction methods have made significant progress in shape estimation, but high-fidelity
            facial albedo reconstruction remains challenging. Existing methods depend on expensive light-stage captured
            data to learn facial albedo maps. However, a lack of diversity in subjects limits their ability to recover
            high-fidelity results. In this paper, we present a novel facial albedo reconstruction model, HiFiAlbedo,
            which recovers the albedo map directly from a single image without the need for captured albedo data. Our
            key insight is that the albedo map is the illumination invariant texture map, which enables us to use
            inexpensive texture data to derive an albedo estimation by eliminating illumination. To achieve this, we
            first collect large-scale ultra-high-resolution facial images and train a high-fidelity facial texture
            codebook. By using the FFHQ dataset and limited UV textures, we then fine-tune the encoder for texture
            reconstruction from the input image with adversarial supervision in both image and UV space. Finally, we
            train a cross-attention module and utilize group identity loss to learn the adaptation from facial texture
            to the albedo domain. Extensive experimentation has demonstrated that our method exhibits excellent
            generalizability and is capable of achieving high-fidelity results for in-the-wild facial albedo recovery.
            Our code, pre-trained weights, and training data will be made publicly available.
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <h3 class="title is-3">Personalized Facial Appearance Editing</h3>
      <div class="video_container">

        <div class="text_column">
          <p>Single-Image Albedo</p>
          <p>Multi-Image Albedo</p>
          <p>Render 1</p>
          <p>Render 2</p>
        </div>

        <div class="video_column">
          <video autoplay loop muted>
            <source src="static/videos/id_00_00.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_00_01.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_00_02.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_00_03.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <!-- <h3 class="title is-4">Expression Change</h3> -->
        </div>


        <div class="video_column">
          <video autoplay loop muted>
            <source src="static/videos/id_01_00.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_01_01.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_01_02.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_01_03.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <!-- <h3 class="title is-4">Lighting Change</h3> -->
        </div>


        <div class="video_column">
          <video autoplay loop muted>
            <source src="static/videos/id_02_00.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_02_01.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_02_02.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_02_03.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <!-- <h3 class="title is-4">Pose Change</h3> -->
        </div>


        <div class="video_column">
          <video autoplay loop muted>
            <source src="static/videos/id_03_00.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_03_01.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_03_02.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <video autoplay loop muted>
            <source src="static/videos/id_03_03.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <!-- <h3 class="title is-4">Lighting Change</h3> -->
        </div>
      </div>

      <br>
      <br>

      <!-- <div class="columns is-centered">
        <div class="column is-9">
          <h3 class="title is-3">Mix and Match: <br> Physical Buffers and Global Latent Code</h3>
          <video autoplay loop muted>
            <source src="static/videos/animation_mixmatch.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <h2 class="subtitle has-text-justified" style="font-size:18px;">
            We mix the physical buffers from one image and the global latent code from another image to demonstrate how
            the two conditions encode disentangled information.
          </h2>
        </div>
      </div>

      <br>
      <br>

      <div class="columns is-centered">
        <div class="column is-9">
          <h3 class="title is-3">Swapping Personalized Models</h3>
          <video autoplay loop muted>
            <source src="static/videos/animation_fy.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <h2 class="subtitle has-text-justified" style="font-size:18px;">
            We demonstrate the power of personalized priors by running one person’s model on other identities. This
            creates the effect of “adding” one person’s identity to another person.
          </h2>
        </div>
      </div>
    </div> -->




  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">BibTeX</h2>
      <pre><code>@InProceedings{ding2023diffusionrig,
      author    = {Zheng Ding, Cecilia Zhang, Zhihao Xia, Lars Jebe, Zhuowen Tu and Xiuming Zhang},
      title     = {DiffusionRig: Learning Personalized Priors for Facial Appearance Editing},
      booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
      year      = {2023},
}</code></pre>
    </div>
  </section>


  <!-- <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This website's source code is borrowed from the <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->

</body>

</html>